{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Insurance cost prediction using linear regression\n",
    "\n",
    "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
    "\n",
    "\n",
    "We will create a model with the following steps:\n",
    "1. Download and explore the dataset\n",
    "2. Prepare the dataset for training\n",
    "3. Create a linear regression model\n",
    "4. Train the model to fit the data\n",
    "5. Make predictions using the trained model\n",
    "\n",
    "\n",
    "This assignment builds upon the concepts from the first 2 lectures. It will help to review these Jupyter notebooks:\n",
    "- PyTorch basics: https://jovian.ml/aakashns/01-pytorch-basics\n",
    "- Linear Regression: https://jovian.ml/aakashns/02-linear-regression\n",
    "- Logistic Regression: https://jovian.ml/aakashns/03-logistic-regression\n",
    "- Linear regression (minimal): https://jovian.ml/aakashns/housing-linear-minimal\n",
    "- Logistic regression (minimal): https://jovian.ml/aakashns/mnist-logistic-minimal\n",
    "\n",
    "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run the commands below if imports fail\n",
    "# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
    "# !pip install matplotlib --upgrade --quiet\n",
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import jovian\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download and explore the data\n",
    "\n",
    "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae7c4a58f9a4f67b9e03b616badbf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
    "DATA_FILENAME = \"insurance.csv\"\n",
    "download_url(DATASET_URL, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = \"rallet\" # at least 5 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['region'], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>29</td>\n",
       "      <td>male</td>\n",
       "      <td>34.43500</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>48152.292340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>30.59380</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>5560.436808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>61</td>\n",
       "      <td>male</td>\n",
       "      <td>32.89755</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>14195.374038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>59</td>\n",
       "      <td>male</td>\n",
       "      <td>23.95900</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>13309.850880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>30.08940</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>6680.146464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     sex       bmi  children smoker     region       charges\n",
       "739   29    male  34.43500         2    yes  southwest  48152.292340\n",
       "662   32  female  30.59380         1     no  northeast   5560.436808\n",
       "642   61    male  32.89755         0     no  northeast  14195.374038\n",
       "841   59    male  23.95900         0     no  northeast  13309.850880\n",
       "673   41  female  30.08940         0     no  southeast   6680.146464"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us answer some basic questions about the dataset. \n",
    "\n",
    "\n",
    "**Q: How many rows does the dataset have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How many columns doe the dataset have**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "num_cols = dataframe.shape[1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What are the column titles of the input variables?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children', 'smoker', 'region']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols = [c for c in dataframe.columns if c != \"charges\"]\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
    "\n",
    "Hint: `sex` is one of them. List the columns that are not numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'smoker', 'region']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [c for c in dataframe.columns if c not in dataframe._get_numeric_data().columns]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What are the column titles of output/target variable(s)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = [\"charges\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
    "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 1211.623812\n",
      "Max: 68872.06225080001\n",
      "Average: 14250.054914745648\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "print(\"Min: {}\".format(dataframe[\"charges\"].min()))\n",
    "print(\"Max: {}\".format(dataframe[\"charges\"].max()))\n",
    "print(\"Average: {}\".format(dataframe[\"charges\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(dataframe[\"charges\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project=project_name, environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset for training\n",
    "\n",
    "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        print(col)\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    print(input_cols)\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "smoker\n",
      "region\n",
      "['age', 'sex', 'bmi', 'children', 'smoker', 'region']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[29.     ,  1.     , 34.435  ,  2.     ,  1.     ,  3.     ],\n",
       "        [32.     ,  0.     , 30.5938 ,  1.     ,  0.     ,  0.     ],\n",
       "        [61.     ,  1.     , 32.89755,  0.     ,  0.     ,  0.     ],\n",
       "        ...,\n",
       "        [18.     ,  1.     , 51.5361 ,  0.     ,  0.     ,  2.     ],\n",
       "        [50.     ,  0.     , 22.8338 ,  2.     ,  0.     ,  2.     ],\n",
       "        [20.     ,  0.     , 30.5162 ,  0.     ,  0.     ,  2.     ]]),\n",
       " array([[48152.2923396],\n",
       "        [ 5560.436808 ],\n",
       "        [14195.374038 ],\n",
       "        ...,\n",
       "        [ 1256.539716 ],\n",
       "        [10915.798248 ],\n",
       "        [ 2028.163752 ]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs_array).type(torch.float32)\n",
    "targets = torch.from_numpy(targets_array).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.2 # between 0.1 and 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017, 254)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create data loaders for training & validation.\n",
    "\n",
    "**Q: Pick a batch size for the data loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 # The batch size is usually set between 64 and 256. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a batch of data to verify everything is working fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[20.0000,  1.0000, 32.3301,  0.0000,  0.0000,  2.0000],\n",
      "        [53.0000,  1.0000, 35.5020,  3.0000,  0.0000,  3.0000],\n",
      "        [22.0000,  1.0000, 36.4914,  1.0000,  1.0000,  2.0000],\n",
      "        ...,\n",
      "        [37.0000,  0.0000, 16.7713,  2.0000,  0.0000,  0.0000],\n",
      "        [49.0000,  1.0000, 28.9351,  1.0000,  0.0000,  0.0000],\n",
      "        [29.0000,  1.0000, 27.1018,  0.0000,  0.0000,  2.0000]])\n",
      "targets: tensor([[ 1502.8510],\n",
      "        [12165.7041],\n",
      "        [40138.3750],\n",
      "        [ 4176.2036],\n",
      "        [20480.2266],\n",
      "        [ 7716.4517],\n",
      "        [ 8250.5713],\n",
      "        [ 1840.9336],\n",
      "        [ 2438.0732],\n",
      "        [ 9960.1943],\n",
      "        [ 2340.0706],\n",
      "        [15533.3262],\n",
      "        [ 2610.3113],\n",
      "        [15100.3984],\n",
      "        [39850.6328],\n",
      "        [ 6383.8193],\n",
      "        [21528.1348],\n",
      "        [36450.3164],\n",
      "        [15052.6797],\n",
      "        [ 5873.8491],\n",
      "        [ 1226.8159],\n",
      "        [23736.9707],\n",
      "        [24889.2109],\n",
      "        [ 5274.5752],\n",
      "        [ 1989.9205],\n",
      "        [ 3621.5466],\n",
      "        [44216.5898],\n",
      "        [ 7961.5137],\n",
      "        [13007.8896],\n",
      "        [20999.8066],\n",
      "        [37047.4219],\n",
      "        [23516.2676],\n",
      "        [ 9231.5068],\n",
      "        [ 8946.3750],\n",
      "        [ 3663.7544],\n",
      "        [ 5131.1558],\n",
      "        [20898.3984],\n",
      "        [ 2792.0906],\n",
      "        [21162.3945],\n",
      "        [12253.1602],\n",
      "        [15563.8066],\n",
      "        [31472.6699],\n",
      "        [ 5549.3174],\n",
      "        [12370.3428],\n",
      "        [ 3881.7046],\n",
      "        [ 7199.5425],\n",
      "        [49358.1836],\n",
      "        [12478.5615],\n",
      "        [15426.1357],\n",
      "        [ 1762.3669],\n",
      "        [ 6447.3008],\n",
      "        [44252.0977],\n",
      "        [ 2301.1299],\n",
      "        [26481.8848],\n",
      "        [15632.6494],\n",
      "        [ 9908.0664],\n",
      "        [14282.6680],\n",
      "        [ 6864.7725],\n",
      "        [13334.9453],\n",
      "        [ 2792.7188],\n",
      "        [13425.4297],\n",
      "        [ 7247.0073],\n",
      "        [13478.0859],\n",
      "        [12371.7021],\n",
      "        [24910.6543],\n",
      "        [23056.6016],\n",
      "        [10203.0303],\n",
      "        [ 3070.1816],\n",
      "        [ 7723.1792],\n",
      "        [21247.2031],\n",
      "        [ 9989.4551],\n",
      "        [ 7786.2510],\n",
      "        [ 7016.6367],\n",
      "        [ 4576.0967],\n",
      "        [ 1232.7607],\n",
      "        [ 7079.4761],\n",
      "        [ 5179.3096],\n",
      "        [52795.9453],\n",
      "        [37387.2695],\n",
      "        [13113.9854],\n",
      "        [ 5687.6748],\n",
      "        [49820.9688],\n",
      "        [10528.8232],\n",
      "        [14488.2412],\n",
      "        [13525.4932],\n",
      "        [ 5682.3872],\n",
      "        [ 1884.0222],\n",
      "        [ 3878.7983],\n",
      "        [27360.0000],\n",
      "        [ 2586.7852],\n",
      "        [14695.9580],\n",
      "        [ 4057.1514],\n",
      "        [ 4607.4590],\n",
      "        [ 1830.3801],\n",
      "        [ 1228.4673],\n",
      "        [12174.1182],\n",
      "        [21076.7852],\n",
      "        [10395.9932],\n",
      "        [ 9872.2275],\n",
      "        [ 6950.4736],\n",
      "        [ 4768.3716],\n",
      "        [11959.0303],\n",
      "        [11672.0850],\n",
      "        [38330.9727],\n",
      "        [ 3287.7502],\n",
      "        [ 8939.7246],\n",
      "        [20564.1465],\n",
      "        [ 4313.7119],\n",
      "        [50327.0352],\n",
      "        [20997.7422],\n",
      "        [20345.8008],\n",
      "        [40616.1289],\n",
      "        [ 1984.2159],\n",
      "        [23392.7246],\n",
      "        [11239.6523],\n",
      "        [ 1841.0762],\n",
      "        [ 3463.0107],\n",
      "        [20545.1211],\n",
      "        [ 5308.2646],\n",
      "        [ 1808.6029],\n",
      "        [49955.5234],\n",
      "        [15121.3896],\n",
      "        [10481.0410],\n",
      "        [ 1238.5403],\n",
      "        [ 3760.4175],\n",
      "        [ 1636.5725],\n",
      "        [10969.3262],\n",
      "        [12153.6943],\n",
      "        [16759.6348],\n",
      "        [ 5737.1436],\n",
      "        [11803.1572],\n",
      "        [10571.9756],\n",
      "        [ 6568.9976],\n",
      "        [21102.3828],\n",
      "        [22405.6680],\n",
      "        [ 3323.2632],\n",
      "        [25711.8203],\n",
      "        [ 9533.3867],\n",
      "        [ 2682.4348],\n",
      "        [21900.0312],\n",
      "        [14194.8037],\n",
      "        [23967.8320],\n",
      "        [ 2143.2095],\n",
      "        [16374.4570],\n",
      "        [ 7311.8081],\n",
      "        [ 3838.5393],\n",
      "        [21853.6426],\n",
      "        [12682.7627],\n",
      "        [ 4363.8027],\n",
      "        [ 9217.4453],\n",
      "        [18552.9766],\n",
      "        [ 3885.4036],\n",
      "        [ 6900.5283],\n",
      "        [ 1778.1440],\n",
      "        [ 4166.3799],\n",
      "        [ 8930.5674],\n",
      "        [ 8707.7852],\n",
      "        [11560.8271],\n",
      "        [14091.1191],\n",
      "        [40856.1016],\n",
      "        [19675.6152],\n",
      "        [22435.5176],\n",
      "        [ 7171.7886],\n",
      "        [ 8899.8369],\n",
      "        [12829.4326],\n",
      "        [14260.6289],\n",
      "        [ 1770.7281],\n",
      "        [ 4820.2617],\n",
      "        [ 2124.3845],\n",
      "        [ 9292.1289],\n",
      "        [16799.6035],\n",
      "        [ 9203.7637],\n",
      "        [23915.5547],\n",
      "        [ 3769.7930],\n",
      "        [ 5535.2329],\n",
      "        [ 8428.4932],\n",
      "        [ 9317.7441],\n",
      "        [ 6905.0918],\n",
      "        [11151.2227],\n",
      "        [ 4031.2351],\n",
      "        [50819.9766],\n",
      "        [ 6991.9341],\n",
      "        [ 2397.0007],\n",
      "        [ 1762.2018],\n",
      "        [ 8891.7451],\n",
      "        [ 1845.6398],\n",
      "        [12832.5273],\n",
      "        [ 1856.9912],\n",
      "        [10915.7979],\n",
      "        [ 4698.5557],\n",
      "        [ 9304.5244],\n",
      "        [12788.0371],\n",
      "        [ 7718.8735],\n",
      "        [ 6080.8945],\n",
      "        [37195.0430],\n",
      "        [14548.4688],\n",
      "        [ 4805.4189],\n",
      "        [47952.4375],\n",
      "        [46714.7695],\n",
      "        [11450.5762],\n",
      "        [ 4468.5244],\n",
      "        [17766.9668],\n",
      "        [ 3763.0774],\n",
      "        [ 5234.6738],\n",
      "        [ 8891.2500],\n",
      "        [ 7323.8623],\n",
      "        [ 4819.7397],\n",
      "        [12608.0605],\n",
      "        [27558.4824],\n",
      "        [28100.4668],\n",
      "        [ 7643.3647],\n",
      "        [ 6101.6924],\n",
      "        [ 1866.0078],\n",
      "        [30607.4043],\n",
      "        [19309.2129],\n",
      "        [14952.0664],\n",
      "        [ 2915.5339],\n",
      "        [ 5224.5889],\n",
      "        [40045.7227],\n",
      "        [18118.4082],\n",
      "        [ 2140.1084],\n",
      "        [51728.5352],\n",
      "        [ 1222.0271],\n",
      "        [13064.3828],\n",
      "        [14534.5977],\n",
      "        [44207.0234],\n",
      "        [ 1657.0488],\n",
      "        [13224.0938],\n",
      "        [ 4187.4888],\n",
      "        [ 6883.4419],\n",
      "        [ 3414.3704],\n",
      "        [29942.2324],\n",
      "        [20269.1562],\n",
      "        [ 6867.4785],\n",
      "        [12590.3359],\n",
      "        [ 5673.8062],\n",
      "        [27733.0801],\n",
      "        [47977.7070],\n",
      "        [ 2272.4424],\n",
      "        [ 8966.7383],\n",
      "        [12407.3818],\n",
      "        [ 3841.4761],\n",
      "        [ 4402.6167],\n",
      "        [ 3212.0562],\n",
      "        [ 3521.0149],\n",
      "        [ 1900.0851],\n",
      "        [19681.3281],\n",
      "        [11655.3164],\n",
      "        [ 2058.8669],\n",
      "        [ 2382.4592],\n",
      "        [48152.2930],\n",
      "        [ 6914.4746],\n",
      "        [29533.7246],\n",
      "        [ 7428.2188],\n",
      "        [10031.0684],\n",
      "        [ 3096.4893]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our work by committing to Jovian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project=\"02-insurance-linear-regression\", environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Linear Regression Model\n",
    "\n",
    "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size, output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
    "\n",
    "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        #loss = F.mse_loss(out, targets) \n",
    "        #loss = F.poisson_nll_loss(out, targets) \n",
    "        loss = F.l1_loss(out, targets) \n",
    "        #loss = F.nll_loss(out, targets) \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        #loss = F.mse_loss(out, targets)\n",
    "        #loss = F.poisson_nll_loss(out, targets) \n",
    "        loss = F.l1_loss(out, targets) \n",
    "        #loss = F.nll_loss(out, targets)\n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the weights and biases of the model using `model.parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2730, -0.2329, -0.0548,  0.2674, -0.0574,  0.0627]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1705], requires_grad=True)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final commit before we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project=\"02-insurance-linear-regression\", environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model to fit the data\n",
    "\n",
    "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 14226.09375}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model, val_loader) # Use the the evaluate function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
    "\n",
    "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 7693.9722\n",
      "Epoch [40], val_loss: 7575.7939\n",
      "Epoch [60], val_loss: 7485.4604\n",
      "Epoch [80], val_loss: 7404.1016\n",
      "Epoch [100], val_loss: 7328.8320\n",
      "Epoch [120], val_loss: 7270.2842\n",
      "Epoch [140], val_loss: 7228.5303\n",
      "Epoch [160], val_loss: 7198.8564\n",
      "Epoch [180], val_loss: 7178.8911\n",
      "Epoch [200], val_loss: 7166.9014\n",
      "Epoch [220], val_loss: 7159.9883\n",
      "Epoch [240], val_loss: 7158.1963\n",
      "Epoch [260], val_loss: 7157.6768\n",
      "Epoch [280], val_loss: 7156.7056\n",
      "Epoch [300], val_loss: 7155.9424\n",
      "Epoch [320], val_loss: 7155.6577\n",
      "Epoch [340], val_loss: 7154.8477\n",
      "Epoch [360], val_loss: 7153.8408\n",
      "Epoch [380], val_loss: 7153.2139\n",
      "Epoch [400], val_loss: 7152.1006\n",
      "Epoch [420], val_loss: 7151.7153\n",
      "Epoch [440], val_loss: 7150.5469\n",
      "Epoch [460], val_loss: 7149.7363\n",
      "Epoch [480], val_loss: 7148.5708\n",
      "Epoch [500], val_loss: 7147.5728\n",
      "Epoch [520], val_loss: 7146.4370\n",
      "Epoch [540], val_loss: 7145.2666\n",
      "Epoch [560], val_loss: 7143.8247\n",
      "Epoch [580], val_loss: 7142.6421\n",
      "Epoch [600], val_loss: 7141.5601\n",
      "Epoch [620], val_loss: 7140.4048\n",
      "Epoch [640], val_loss: 7139.2803\n",
      "Epoch [660], val_loss: 7138.1426\n",
      "Epoch [680], val_loss: 7137.1035\n",
      "Epoch [700], val_loss: 7135.8501\n",
      "Epoch [720], val_loss: 7134.6201\n",
      "Epoch [740], val_loss: 7133.4756\n",
      "Epoch [760], val_loss: 7132.4224\n",
      "Epoch [780], val_loss: 7131.0684\n",
      "Epoch [800], val_loss: 7130.0742\n",
      "Epoch [820], val_loss: 7128.9756\n",
      "Epoch [840], val_loss: 7127.6504\n",
      "Epoch [860], val_loss: 7126.4297\n",
      "Epoch [880], val_loss: 7125.5308\n",
      "Epoch [900], val_loss: 7124.4722\n",
      "Epoch [920], val_loss: 7123.5972\n",
      "Epoch [940], val_loss: 7122.2661\n",
      "Epoch [960], val_loss: 7121.2490\n",
      "Epoch [980], val_loss: 7120.1074\n",
      "Epoch [1000], val_loss: 7119.1807\n",
      "Epoch [1020], val_loss: 7118.1772\n",
      "Epoch [1040], val_loss: 7116.9976\n",
      "Epoch [1060], val_loss: 7116.1318\n",
      "Epoch [1080], val_loss: 7115.2520\n",
      "Epoch [1100], val_loss: 7114.1948\n",
      "Epoch [1120], val_loss: 7113.3320\n",
      "Epoch [1140], val_loss: 7112.5854\n",
      "Epoch [1160], val_loss: 7111.4531\n",
      "Epoch [1180], val_loss: 7110.5737\n",
      "Epoch [1200], val_loss: 7109.5732\n",
      "Epoch [1220], val_loss: 7108.8794\n",
      "Epoch [1240], val_loss: 7107.8306\n",
      "Epoch [1260], val_loss: 7106.9634\n",
      "Epoch [1280], val_loss: 7106.1089\n",
      "Epoch [1300], val_loss: 7105.2617\n",
      "Epoch [1320], val_loss: 7104.5322\n",
      "Epoch [1340], val_loss: 7103.6484\n",
      "Epoch [1360], val_loss: 7102.5059\n",
      "Epoch [1380], val_loss: 7101.9336\n",
      "Epoch [1400], val_loss: 7101.1816\n",
      "Epoch [1420], val_loss: 7100.0352\n",
      "Epoch [1440], val_loss: 7099.1255\n",
      "Epoch [1460], val_loss: 7098.2334\n",
      "Epoch [1480], val_loss: 7097.5474\n",
      "Epoch [1500], val_loss: 7096.3140\n",
      "Epoch [1520], val_loss: 7095.6055\n",
      "Epoch [1540], val_loss: 7094.6826\n",
      "Epoch [1560], val_loss: 7093.8330\n",
      "Epoch [1580], val_loss: 7093.2041\n",
      "Epoch [1600], val_loss: 7092.2051\n",
      "Epoch [1620], val_loss: 7091.4893\n",
      "Epoch [1640], val_loss: 7090.6025\n",
      "Epoch [1660], val_loss: 7089.7471\n",
      "Epoch [1680], val_loss: 7088.9297\n",
      "Epoch [1700], val_loss: 7088.2437\n",
      "Epoch [1720], val_loss: 7087.4106\n",
      "Epoch [1740], val_loss: 7086.4702\n",
      "Epoch [1760], val_loss: 7085.7827\n",
      "Epoch [1780], val_loss: 7084.5806\n",
      "Epoch [1800], val_loss: 7083.6421\n",
      "Epoch [1820], val_loss: 7083.0679\n",
      "Epoch [1840], val_loss: 7082.2363\n",
      "Epoch [1860], val_loss: 7081.2778\n",
      "Epoch [1880], val_loss: 7080.2974\n",
      "Epoch [1900], val_loss: 7079.7158\n",
      "Epoch [1920], val_loss: 7079.2764\n",
      "Epoch [1940], val_loss: 7077.6777\n",
      "Epoch [1960], val_loss: 7077.2637\n",
      "Epoch [1980], val_loss: 7076.9775\n",
      "Epoch [2000], val_loss: 7075.8936\n",
      "Epoch [2020], val_loss: 7075.2695\n",
      "Epoch [2040], val_loss: 7074.5825\n",
      "Epoch [2060], val_loss: 7073.6870\n",
      "Epoch [2080], val_loss: 7073.0708\n",
      "Epoch [2100], val_loss: 7072.3223\n",
      "Epoch [2120], val_loss: 7071.6943\n",
      "Epoch [2140], val_loss: 7070.9292\n",
      "Epoch [2160], val_loss: 7070.3408\n",
      "Epoch [2180], val_loss: 7069.6162\n",
      "Epoch [2200], val_loss: 7068.6875\n",
      "Epoch [2220], val_loss: 7067.7427\n",
      "Epoch [2240], val_loss: 7067.3042\n",
      "Epoch [2260], val_loss: 7066.4521\n",
      "Epoch [2280], val_loss: 7065.5957\n",
      "Epoch [2300], val_loss: 7065.1606\n",
      "Epoch [2320], val_loss: 7064.0762\n",
      "Epoch [2340], val_loss: 7063.0796\n",
      "Epoch [2360], val_loss: 7063.0615\n",
      "Epoch [2380], val_loss: 7062.6279\n",
      "Epoch [2400], val_loss: 7061.9375\n",
      "Epoch [2420], val_loss: 7060.6479\n",
      "Epoch [2440], val_loss: 7060.1035\n",
      "Epoch [2460], val_loss: 7059.6958\n",
      "Epoch [2480], val_loss: 7058.8594\n",
      "Epoch [2500], val_loss: 7058.3467\n",
      "Epoch [2520], val_loss: 7057.8018\n",
      "Epoch [2540], val_loss: 7056.5376\n",
      "Epoch [2560], val_loss: 7055.3511\n",
      "Epoch [2580], val_loss: 7055.1108\n",
      "Epoch [2600], val_loss: 7054.5903\n",
      "Epoch [2620], val_loss: 7053.8696\n",
      "Epoch [2640], val_loss: 7053.0811\n",
      "Epoch [2660], val_loss: 7052.4956\n",
      "Epoch [2680], val_loss: 7051.4277\n",
      "Epoch [2700], val_loss: 7051.2129\n",
      "Epoch [2720], val_loss: 7050.4033\n",
      "Epoch [2740], val_loss: 7050.1318\n",
      "Epoch [2760], val_loss: 7049.5566\n",
      "Epoch [2780], val_loss: 7048.8867\n",
      "Epoch [2800], val_loss: 7047.5952\n",
      "Epoch [2820], val_loss: 7047.5234\n",
      "Epoch [2840], val_loss: 7046.6782\n",
      "Epoch [2860], val_loss: 7045.6436\n",
      "Epoch [2880], val_loss: 7046.1250\n",
      "Epoch [2900], val_loss: 7044.7876\n",
      "Epoch [2920], val_loss: 7044.2466\n",
      "Epoch [2940], val_loss: 7043.5889\n",
      "Epoch [2960], val_loss: 7042.9443\n",
      "Epoch [2980], val_loss: 7042.3281\n",
      "Epoch [3000], val_loss: 7041.9404\n",
      "Epoch [3020], val_loss: 7041.0234\n",
      "Epoch [3040], val_loss: 7040.4233\n",
      "Epoch [3060], val_loss: 7039.9746\n",
      "Epoch [3080], val_loss: 7039.0625\n",
      "Epoch [3100], val_loss: 7038.2705\n",
      "Epoch [3120], val_loss: 7038.0347\n",
      "Epoch [3140], val_loss: 7037.9092\n",
      "Epoch [3160], val_loss: 7036.5122\n",
      "Epoch [3180], val_loss: 7036.1655\n",
      "Epoch [3200], val_loss: 7035.6768\n",
      "Epoch [3220], val_loss: 7034.4741\n",
      "Epoch [3240], val_loss: 7035.1099\n",
      "Epoch [3260], val_loss: 7034.1904\n",
      "Epoch [3280], val_loss: 7033.6787\n",
      "Epoch [3300], val_loss: 7032.6753\n",
      "Epoch [3320], val_loss: 7032.3730\n",
      "Epoch [3340], val_loss: 7031.7505\n",
      "Epoch [3360], val_loss: 7031.0288\n",
      "Epoch [3380], val_loss: 7030.3403\n",
      "Epoch [3400], val_loss: 7029.6372\n",
      "Epoch [3420], val_loss: 7029.4741\n",
      "Epoch [3440], val_loss: 7028.3022\n",
      "Epoch [3460], val_loss: 7028.9585\n",
      "Epoch [3480], val_loss: 7027.6260\n",
      "Epoch [3500], val_loss: 7026.8750\n",
      "Epoch [3520], val_loss: 7026.0171\n",
      "Epoch [3540], val_loss: 7025.9624\n",
      "Epoch [3560], val_loss: 7025.4805\n",
      "Epoch [3580], val_loss: 7024.6636\n",
      "Epoch [3600], val_loss: 7023.8096\n",
      "Epoch [3620], val_loss: 7023.8506\n",
      "Epoch [3640], val_loss: 7023.6460\n",
      "Epoch [3660], val_loss: 7022.8447\n",
      "Epoch [3680], val_loss: 7022.7534\n",
      "Epoch [3700], val_loss: 7021.6338\n",
      "Epoch [3720], val_loss: 7020.7808\n",
      "Epoch [3740], val_loss: 7020.3618\n",
      "Epoch [3760], val_loss: 7019.7021\n",
      "Epoch [3780], val_loss: 7019.3335\n",
      "Epoch [3800], val_loss: 7018.8999\n",
      "Epoch [3820], val_loss: 7018.1572\n",
      "Epoch [3840], val_loss: 7018.2500\n",
      "Epoch [3860], val_loss: 7017.2446\n",
      "Epoch [3880], val_loss: 7016.7461\n",
      "Epoch [3900], val_loss: 7016.3599\n",
      "Epoch [3920], val_loss: 7015.8647\n",
      "Epoch [3940], val_loss: 7015.3105\n",
      "Epoch [3960], val_loss: 7014.5693\n",
      "Epoch [3980], val_loss: 7014.4478\n",
      "Epoch [4000], val_loss: 7013.7637\n",
      "Epoch [4020], val_loss: 7013.2744\n",
      "Epoch [4040], val_loss: 7012.9121\n",
      "Epoch [4060], val_loss: 7012.2124\n",
      "Epoch [4080], val_loss: 7011.8237\n",
      "Epoch [4100], val_loss: 7011.2705\n",
      "Epoch [4120], val_loss: 7010.8799\n",
      "Epoch [4140], val_loss: 7010.2705\n",
      "Epoch [4160], val_loss: 7009.7881\n",
      "Epoch [4180], val_loss: 7009.3027\n",
      "Epoch [4200], val_loss: 7009.4224\n",
      "Epoch [4220], val_loss: 7008.2397\n",
      "Epoch [4240], val_loss: 7007.9019\n",
      "Epoch [4260], val_loss: 7007.7402\n",
      "Epoch [4280], val_loss: 7006.7573\n",
      "Epoch [4300], val_loss: 7006.6357\n",
      "Epoch [4320], val_loss: 7006.0293\n",
      "Epoch [4340], val_loss: 7005.2510\n",
      "Epoch [4360], val_loss: 7005.1587\n",
      "Epoch [4380], val_loss: 7004.5737\n",
      "Epoch [4400], val_loss: 7004.3169\n",
      "Epoch [4420], val_loss: 7003.3833\n",
      "Epoch [4440], val_loss: 7003.4497\n",
      "Epoch [4460], val_loss: 7002.7261\n",
      "Epoch [4480], val_loss: 7002.1484\n",
      "Epoch [4500], val_loss: 7001.8501\n",
      "Epoch [4520], val_loss: 7001.5034\n",
      "Epoch [4540], val_loss: 7000.7383\n",
      "Epoch [4560], val_loss: 7000.1650\n",
      "Epoch [4580], val_loss: 6999.9951\n",
      "Epoch [4600], val_loss: 6999.1846\n",
      "Epoch [4620], val_loss: 6999.4556\n",
      "Epoch [4640], val_loss: 6998.5483\n",
      "Epoch [4660], val_loss: 6998.2153\n",
      "Epoch [4680], val_loss: 6997.6870\n",
      "Epoch [4700], val_loss: 6997.5615\n",
      "Epoch [4720], val_loss: 6996.5469\n",
      "Epoch [4740], val_loss: 6996.2441\n",
      "Epoch [4760], val_loss: 6995.9268\n",
      "Epoch [4780], val_loss: 6995.1626\n",
      "Epoch [4800], val_loss: 6994.8462\n",
      "Epoch [4820], val_loss: 6994.5107\n",
      "Epoch [4840], val_loss: 6993.6294\n",
      "Epoch [4860], val_loss: 6993.4668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4880], val_loss: 6992.7944\n",
      "Epoch [4900], val_loss: 6992.0439\n",
      "Epoch [4920], val_loss: 6991.8403\n",
      "Epoch [4940], val_loss: 6991.2529\n",
      "Epoch [4960], val_loss: 6990.6665\n",
      "Epoch [4980], val_loss: 6990.5913\n",
      "Epoch [5000], val_loss: 6989.8198\n",
      "Epoch [5020], val_loss: 6989.5420\n",
      "Epoch [5040], val_loss: 6988.8286\n",
      "Epoch [5060], val_loss: 6988.4316\n",
      "Epoch [5080], val_loss: 6987.9243\n",
      "Epoch [5100], val_loss: 6987.5293\n",
      "Epoch [5120], val_loss: 6987.0347\n",
      "Epoch [5140], val_loss: 6986.4375\n",
      "Epoch [5160], val_loss: 6986.1094\n",
      "Epoch [5180], val_loss: 6985.3105\n",
      "Epoch [5200], val_loss: 6985.3232\n",
      "Epoch [5220], val_loss: 6984.3730\n",
      "Epoch [5240], val_loss: 6984.0220\n",
      "Epoch [5260], val_loss: 6983.3838\n",
      "Epoch [5280], val_loss: 6983.5425\n",
      "Epoch [5300], val_loss: 6982.6362\n",
      "Epoch [5320], val_loss: 6982.1558\n",
      "Epoch [5340], val_loss: 6981.9341\n",
      "Epoch [5360], val_loss: 6981.2080\n",
      "Epoch [5380], val_loss: 6980.7393\n",
      "Epoch [5400], val_loss: 6980.4912\n",
      "Epoch [5420], val_loss: 6980.0737\n",
      "Epoch [5440], val_loss: 6979.2754\n",
      "Epoch [5460], val_loss: 6978.9873\n",
      "Epoch [5480], val_loss: 6978.3984\n",
      "Epoch [5500], val_loss: 6977.8037\n",
      "Epoch [5520], val_loss: 6977.6382\n",
      "Epoch [5540], val_loss: 6977.0610\n",
      "Epoch [5560], val_loss: 6976.7520\n",
      "Epoch [5580], val_loss: 6976.3008\n",
      "Epoch [5600], val_loss: 6975.8081\n",
      "Epoch [5620], val_loss: 6975.4873\n",
      "Epoch [5640], val_loss: 6974.7100\n",
      "Epoch [5660], val_loss: 6974.4521\n",
      "Epoch [5680], val_loss: 6973.6929\n",
      "Epoch [5700], val_loss: 6973.4312\n",
      "Epoch [5720], val_loss: 6973.1284\n",
      "Epoch [5740], val_loss: 6972.3076\n",
      "Epoch [5760], val_loss: 6971.9238\n",
      "Epoch [5780], val_loss: 6971.3560\n",
      "Epoch [5800], val_loss: 6971.0083\n",
      "Epoch [5820], val_loss: 6970.5474\n",
      "Epoch [5840], val_loss: 6970.3584\n",
      "Epoch [5860], val_loss: 6969.3760\n",
      "Epoch [5880], val_loss: 6969.6187\n",
      "Epoch [5900], val_loss: 6968.7324\n",
      "Epoch [5920], val_loss: 6968.3042\n",
      "Epoch [5940], val_loss: 6968.0190\n",
      "Epoch [5960], val_loss: 6967.3198\n",
      "Epoch [5980], val_loss: 6966.9072\n",
      "Epoch [6000], val_loss: 6966.3306\n",
      "Epoch [6020], val_loss: 6965.9414\n",
      "Epoch [6040], val_loss: 6965.5581\n",
      "Epoch [6060], val_loss: 6964.9038\n",
      "Epoch [6080], val_loss: 6964.8301\n",
      "Epoch [6100], val_loss: 6964.2441\n",
      "Epoch [6120], val_loss: 6963.7520\n",
      "Epoch [6140], val_loss: 6963.3589\n",
      "Epoch [6160], val_loss: 6962.7720\n",
      "Epoch [6180], val_loss: 6962.3843\n",
      "Epoch [6200], val_loss: 6961.5547\n",
      "Epoch [6220], val_loss: 6961.2295\n",
      "Epoch [6240], val_loss: 6960.8452\n",
      "Epoch [6260], val_loss: 6960.5728\n",
      "Epoch [6280], val_loss: 6959.8257\n",
      "Epoch [6300], val_loss: 6959.6108\n",
      "Epoch [6320], val_loss: 6959.0200\n",
      "Epoch [6340], val_loss: 6958.7544\n",
      "Epoch [6360], val_loss: 6958.0669\n",
      "Epoch [6380], val_loss: 6958.0142\n",
      "Epoch [6400], val_loss: 6957.1279\n",
      "Epoch [6420], val_loss: 6956.8862\n",
      "Epoch [6440], val_loss: 6956.6841\n",
      "Epoch [6460], val_loss: 6955.7646\n",
      "Epoch [6480], val_loss: 6955.2939\n",
      "Epoch [6500], val_loss: 6954.8911\n",
      "Epoch [6520], val_loss: 6953.9897\n",
      "Epoch [6540], val_loss: 6953.9443\n",
      "Epoch [6560], val_loss: 6953.3564\n",
      "Epoch [6580], val_loss: 6952.7085\n",
      "Epoch [6600], val_loss: 6952.6167\n",
      "Epoch [6620], val_loss: 6952.0303\n",
      "Epoch [6640], val_loss: 6951.3340\n",
      "Epoch [6660], val_loss: 6950.9873\n",
      "Epoch [6680], val_loss: 6950.7437\n",
      "Epoch [6700], val_loss: 6950.0532\n",
      "Epoch [6720], val_loss: 6949.8560\n",
      "Epoch [6740], val_loss: 6949.3618\n",
      "Epoch [6760], val_loss: 6948.7549\n",
      "Epoch [6780], val_loss: 6948.3076\n",
      "Epoch [6800], val_loss: 6947.9429\n",
      "Epoch [6820], val_loss: 6947.2637\n",
      "Epoch [6840], val_loss: 6946.8726\n",
      "Epoch [6860], val_loss: 6946.3384\n",
      "Epoch [6880], val_loss: 6945.9863\n",
      "Epoch [6900], val_loss: 6945.4834\n",
      "Epoch [6920], val_loss: 6944.9912\n",
      "Epoch [6940], val_loss: 6944.3379\n",
      "Epoch [6960], val_loss: 6944.2266\n",
      "Epoch [6980], val_loss: 6943.8394\n",
      "Epoch [7000], val_loss: 6943.0830\n",
      "Epoch [7020], val_loss: 6942.6855\n",
      "Epoch [7040], val_loss: 6942.3247\n",
      "Epoch [7060], val_loss: 6942.2295\n",
      "Epoch [7080], val_loss: 6941.3154\n",
      "Epoch [7100], val_loss: 6940.8359\n",
      "Epoch [7120], val_loss: 6940.3267\n",
      "Epoch [7140], val_loss: 6940.0439\n",
      "Epoch [7160], val_loss: 6939.8340\n",
      "Epoch [7180], val_loss: 6939.0610\n",
      "Epoch [7200], val_loss: 6938.6963\n",
      "Epoch [7220], val_loss: 6937.9141\n",
      "Epoch [7240], val_loss: 6937.7144\n",
      "Epoch [7260], val_loss: 6937.3701\n",
      "Epoch [7280], val_loss: 6936.5645\n",
      "Epoch [7300], val_loss: 6936.2114\n",
      "Epoch [7320], val_loss: 6935.9907\n",
      "Epoch [7340], val_loss: 6935.3506\n",
      "Epoch [7360], val_loss: 6934.8804\n",
      "Epoch [7380], val_loss: 6934.6973\n",
      "Epoch [7400], val_loss: 6934.0674\n",
      "Epoch [7420], val_loss: 6933.4829\n",
      "Epoch [7440], val_loss: 6933.4219\n",
      "Epoch [7460], val_loss: 6932.5952\n",
      "Epoch [7480], val_loss: 6931.9888\n",
      "Epoch [7500], val_loss: 6931.9565\n",
      "Epoch [7520], val_loss: 6931.3115\n",
      "Epoch [7540], val_loss: 6931.0049\n",
      "Epoch [7560], val_loss: 6930.5259\n",
      "Epoch [7580], val_loss: 6929.9058\n",
      "Epoch [7600], val_loss: 6929.4766\n",
      "Epoch [7620], val_loss: 6929.2998\n",
      "Epoch [7640], val_loss: 6928.8555\n",
      "Epoch [7660], val_loss: 6928.5527\n",
      "Epoch [7680], val_loss: 6927.5977\n",
      "Epoch [7700], val_loss: 6927.3740\n",
      "Epoch [7720], val_loss: 6926.9619\n",
      "Epoch [7740], val_loss: 6926.7524\n",
      "Epoch [7760], val_loss: 6926.0645\n",
      "Epoch [7780], val_loss: 6925.5439\n",
      "Epoch [7800], val_loss: 6924.9795\n",
      "Epoch [7820], val_loss: 6924.6333\n",
      "Epoch [7840], val_loss: 6924.0981\n",
      "Epoch [7860], val_loss: 6923.6504\n",
      "Epoch [7880], val_loss: 6923.1880\n",
      "Epoch [7900], val_loss: 6923.0444\n",
      "Epoch [7920], val_loss: 6922.4912\n",
      "Epoch [7940], val_loss: 6922.5820\n",
      "Epoch [7960], val_loss: 6921.3574\n",
      "Epoch [7980], val_loss: 6921.2002\n",
      "Epoch [8000], val_loss: 6920.8979\n",
      "Epoch [8020], val_loss: 6920.3291\n",
      "Epoch [8040], val_loss: 6919.8662\n",
      "Epoch [8060], val_loss: 6919.5796\n",
      "Epoch [8080], val_loss: 6919.0063\n",
      "Epoch [8100], val_loss: 6918.5557\n",
      "Epoch [8120], val_loss: 6917.8267\n",
      "Epoch [8140], val_loss: 6917.7075\n",
      "Epoch [8160], val_loss: 6917.2373\n",
      "Epoch [8180], val_loss: 6916.5469\n",
      "Epoch [8200], val_loss: 6916.5308\n",
      "Epoch [8220], val_loss: 6916.1753\n",
      "Epoch [8240], val_loss: 6915.3872\n",
      "Epoch [8260], val_loss: 6915.0005\n",
      "Epoch [8280], val_loss: 6914.6514\n",
      "Epoch [8300], val_loss: 6914.1572\n",
      "Epoch [8320], val_loss: 6913.7905\n",
      "Epoch [8340], val_loss: 6912.9561\n",
      "Epoch [8360], val_loss: 6912.5483\n",
      "Epoch [8380], val_loss: 6912.0933\n",
      "Epoch [8400], val_loss: 6911.8271\n",
      "Epoch [8420], val_loss: 6911.2310\n",
      "Epoch [8440], val_loss: 6911.2148\n",
      "Epoch [8460], val_loss: 6910.3472\n",
      "Epoch [8480], val_loss: 6910.0869\n",
      "Epoch [8500], val_loss: 6909.9316\n",
      "Epoch [8520], val_loss: 6909.5156\n",
      "Epoch [8540], val_loss: 6908.8057\n",
      "Epoch [8560], val_loss: 6908.4526\n",
      "Epoch [8580], val_loss: 6907.8984\n",
      "Epoch [8600], val_loss: 6907.3413\n",
      "Epoch [8620], val_loss: 6906.8486\n",
      "Epoch [8640], val_loss: 6906.7524\n",
      "Epoch [8660], val_loss: 6906.0522\n",
      "Epoch [8680], val_loss: 6905.7720\n",
      "Epoch [8700], val_loss: 6905.2773\n",
      "Epoch [8720], val_loss: 6904.7729\n",
      "Epoch [8740], val_loss: 6904.3320\n",
      "Epoch [8760], val_loss: 6904.0454\n",
      "Epoch [8780], val_loss: 6903.7065\n",
      "Epoch [8800], val_loss: 6903.1392\n",
      "Epoch [8820], val_loss: 6902.8335\n",
      "Epoch [8840], val_loss: 6902.3140\n",
      "Epoch [8860], val_loss: 6901.9976\n",
      "Epoch [8880], val_loss: 6901.3794\n",
      "Epoch [8900], val_loss: 6900.8257\n",
      "Epoch [8920], val_loss: 6900.6172\n",
      "Epoch [8940], val_loss: 6900.1919\n",
      "Epoch [8960], val_loss: 6899.5830\n",
      "Epoch [8980], val_loss: 6899.3101\n",
      "Epoch [9000], val_loss: 6898.8618\n",
      "Epoch [9020], val_loss: 6898.4849\n",
      "Epoch [9040], val_loss: 6897.8535\n",
      "Epoch [9060], val_loss: 6897.5161\n",
      "Epoch [9080], val_loss: 6897.3120\n",
      "Epoch [9100], val_loss: 6896.6489\n",
      "Epoch [9120], val_loss: 6896.2524\n",
      "Epoch [9140], val_loss: 6896.0298\n",
      "Epoch [9160], val_loss: 6895.5503\n",
      "Epoch [9180], val_loss: 6894.8901\n",
      "Epoch [9200], val_loss: 6894.6943\n",
      "Epoch [9220], val_loss: 6894.1362\n",
      "Epoch [9240], val_loss: 6893.6182\n",
      "Epoch [9260], val_loss: 6893.3652\n",
      "Epoch [9280], val_loss: 6892.7554\n",
      "Epoch [9300], val_loss: 6892.4575\n",
      "Epoch [9320], val_loss: 6891.9395\n",
      "Epoch [9340], val_loss: 6891.9126\n",
      "Epoch [9360], val_loss: 6891.3564\n",
      "Epoch [9380], val_loss: 6890.7856\n",
      "Epoch [9400], val_loss: 6890.3975\n",
      "Epoch [9420], val_loss: 6889.8857\n",
      "Epoch [9440], val_loss: 6889.5532\n",
      "Epoch [9460], val_loss: 6889.1636\n",
      "Epoch [9480], val_loss: 6888.6719\n",
      "Epoch [9500], val_loss: 6888.5825\n",
      "Epoch [9520], val_loss: 6887.7598\n",
      "Epoch [9540], val_loss: 6887.3218\n",
      "Epoch [9560], val_loss: 6887.1021\n",
      "Epoch [9580], val_loss: 6886.5869\n",
      "Epoch [9600], val_loss: 6886.0688\n",
      "Epoch [9620], val_loss: 6885.6899\n",
      "Epoch [9640], val_loss: 6885.5225\n",
      "Epoch [9660], val_loss: 6884.8809\n",
      "Epoch [9680], val_loss: 6884.4097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9700], val_loss: 6884.2871\n",
      "Epoch [9720], val_loss: 6883.5884\n",
      "Epoch [9740], val_loss: 6883.1860\n",
      "Epoch [9760], val_loss: 6882.7368\n",
      "Epoch [9780], val_loss: 6882.3267\n",
      "Epoch [9800], val_loss: 6881.9146\n",
      "Epoch [9820], val_loss: 6881.5728\n",
      "Epoch [9840], val_loss: 6881.2627\n",
      "Epoch [9860], val_loss: 6880.8247\n",
      "Epoch [9880], val_loss: 6880.2471\n",
      "Epoch [9900], val_loss: 6879.8345\n",
      "Epoch [9920], val_loss: 6879.3931\n",
      "Epoch [9940], val_loss: 6878.9932\n",
      "Epoch [9960], val_loss: 6878.7407\n",
      "Epoch [9980], val_loss: 6878.1523\n",
      "Epoch [10000], val_loss: 6877.9067\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "lr = 0.1\n",
    "history = fit(epochs, lr, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What is the final validation loss of your model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = history[epochs-1][\"val_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's log the final validation loss to Jovian and commit the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Metrics logged.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.log_metrics(val_loss=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"benrallet/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/benrallet/02-insurance-linear-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/benrallet/02-insurance-linear-regression'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=\"02-insurance-linear-regression\", environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Make predictions using the trained model\n",
    "\n",
    "**Q: Complete the following function definition to make predictions on a single input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([18.0000,  1.0000, 30.7781,  0.0000,  1.0000,  0.0000])\n",
      "Target: tensor([36431.3008])\n",
      "Prediction: tensor([2823.4941])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[0]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([63.0000,  1.0000, 21.0102,  1.0000,  0.0000,  1.0000])\n",
      "Target: tensor([15497.8428])\n",
      "Prediction: tensor([15197.0117])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[10]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([34.0000,  0.0000, 32.6890,  1.0000,  0.0000,  3.0000])\n",
      "Target: tensor([5413.4688])\n",
      "Prediction: tensor([5999.8340])\n"
     ]
    }
   ],
   "source": [
    "input, target = val_ds[23]\n",
    "predict_single(input, target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you happy with your model's predictions? Try to improve them further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Step 6: Try another dataset & blog about it\n",
    "\n",
    "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or [this one](https://jovian.ml/aakashns/housing-linear-minimal), or [this one](https://jovian.ml/aakashns/mnist-logistic-minimal) ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n",
    "\n",
    "Here are some sources to find good datasets:\n",
    "\n",
    "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
    "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
    "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
    "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
    "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
    "\n",
    "- Interesting title & subtitle\n",
    "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
    "- Downloading & exploring the data\n",
    "- Preparing the data for training\n",
    "- Creating a model using PyTorch\n",
    "- Training the model to fit the data\n",
    "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
    "- Making predictions using the model\n",
    "\n",
    "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
    "\n",
    "Don't forget to share your work on the forum: https://jovian.ml/forum/t/share-your-work-here-assignment-2/4931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(project=project_name, environment=None)\n",
    "#jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}